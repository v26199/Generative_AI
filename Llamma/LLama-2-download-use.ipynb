{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f92dc3",
   "metadata": {},
   "source": [
    "# Quantized Models from the Hugging Face Community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd16c43",
   "metadata": {},
   "source": [
    "The Hugging Face community provides quantized models, which allow us to efficiently and effectively utilize the model on the T4 GPU. It is important to consult reliable sources before using any model.\n",
    "\n",
    "There are several variations available, but the ones that interest us are based on the GGLM library.\n",
    "\n",
    "We can see the different variations that Llama-2-13B-GGML has here.\n",
    "\n",
    "In this case, we will use the model called Llama-2-13B-chat-GGML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce031c90",
   "metadata": {},
   "source": [
    "# 1: Install All the Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec6e2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\r\n"
     ]
    }
   ],
   "source": [
    "# check for GPU avability \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a3bedcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip 23.2.1 from /Users/vishalpatel/anaconda3/lib/python3.11/site-packages/pip (python 3.11)\n",
      "Collecting llama-cpp-python==0.1.78\n",
      "  Downloading llama_cpp_python-0.1.78.tar.gz (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Running command pip subprocess to install build dependencies\n",
      "  Collecting setuptools>=42\n",
      "    Obtaining dependency information for setuptools>=42 from https://files.pythonhosted.org/packages/f7/29/13965af254e3373bceae8fb9a0e6ea0d0e571171b80d6646932131d6439b/setuptools-69.5.1-py3-none-any.whl.metadata\n",
      "    Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Collecting scikit-build>=0.13\n",
      "    Obtaining dependency information for scikit-build>=0.13 from https://files.pythonhosted.org/packages/fa/af/b3ef8fe0bb96bf7308e1f9d196fc069f0c75d9c74cfaad851e418cc704f4/scikit_build-0.17.6-py3-none-any.whl.metadata\n",
      "    Downloading scikit_build-0.17.6-py3-none-any.whl.metadata (14 kB)\n",
      "  Collecting cmake>=3.18\n",
      "    Obtaining dependency information for cmake>=3.18 from https://files.pythonhosted.org/packages/7a/79/041cc6a56334ffa77da4ad101c2327fad6c9c0a87f3aa93178875fb138f1/cmake-3.29.2-py3-none-macosx_10_10_universal2.macosx_10_10_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl.metadata\n",
      "    Downloading cmake-3.29.2-py3-none-macosx_10_10_universal2.macosx_10_10_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl.metadata (6.1 kB)\n",
      "  Collecting ninja\n",
      "    Obtaining dependency information for ninja from https://files.pythonhosted.org/packages/3d/6e/04ed11bb244039908f6f212cb5f3e97933e238655248e4ce307c1687ba1f/ninja-1.11.1.1-py2.py3-none-macosx_10_9_universal2.macosx_10_9_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl.metadata\n",
      "    Downloading ninja-1.11.1.1-py2.py3-none-macosx_10_9_universal2.macosx_10_9_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl.metadata (5.3 kB)\n",
      "  Collecting distro (from scikit-build>=0.13)\n",
      "    Obtaining dependency information for distro from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "    Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Collecting packaging (from scikit-build>=0.13)\n",
      "    Obtaining dependency information for packaging from https://files.pythonhosted.org/packages/49/df/1fceb2f8900f8639e278b056416d49134fb8d84c5942ffaa01ad34782422/packaging-24.0-py3-none-any.whl.metadata\n",
      "    Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Collecting wheel>=0.32.0 (from scikit-build>=0.13)\n",
      "    Obtaining dependency information for wheel>=0.32.0 from https://files.pythonhosted.org/packages/7d/cd/d7460c9a869b16c3dd4e1e403cce337df165368c71d6af229a74699622ce/wheel-0.43.0-py3-none-any.whl.metadata\n",
      "    Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Using cached setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
      "  Downloading scikit_build-0.17.6-py3-none-any.whl (84 kB)\n",
      "  \u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "  \u001b[?25hDownloading cmake-3.29.2-py3-none-macosx_10_10_universal2.macosx_10_10_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl (51.0 MB)\n",
      "  \u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  \u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/51.0 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/51.0 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/51.0 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/51.0 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/51.0 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/51.0 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/51.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/51.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/51.0 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/51.0 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/51.0 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/51.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/51.0 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/51.0 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/51.0 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/51.0 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/51.0 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.3/51.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.4/51.0 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.8/51.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/51.0 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m36.0/51.0 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m37.2/51.0 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m38.9/51.0 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m39.8/51.0 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m41.1/51.0 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m41.9/51.0 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m43.5/51.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m44.9/51.0 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m45.8/51.0 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m47.2/51.0 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m48.5/51.0 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m50.0/51.0 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m51.0/51.0 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m51.0/51.0 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "  \u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-macosx_10_9_universal2.macosx_10_9_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl (270 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/270.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.6/270.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "  \u001b[?25hUsing cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "  Downloading packaging-24.0-py3-none-any.whl (53 kB)\n",
      "  \u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "  \u001b[?25hInstalling collected packages: ninja, wheel, setuptools, packaging, distro, cmake, scikit-build\n",
      "  \u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "  tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "  tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "  conda-repo-cli 1.0.41 requires requests_mock, which is not installed.\n",
      "  spyder 5.4.3 requires pyqt5<5.16, which is not installed.\n",
      "  spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "  pandas-profiling 3.2.0 requires visions[type_image_path]==0.7.4, but you have visions 0.7.5 which is incompatible.\n",
      "  conda-repo-cli 1.0.41 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "  conda-repo-cli 1.0.41 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "  conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.31.0 which is incompatible.\n",
      "  langchain-core 0.1.44 requires packaging<24.0,>=23.2, but you have packaging 24.0 which is incompatible.\n",
      "  python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "  \u001b[0mSuccessfully installed cmake-3.29.2 distro-1.9.0 ninja-1.11.1.1 packaging-24.0 scikit-build-0.17.6 setuptools-69.5.1 wheel-0.43.0\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Running command Getting requirements to build wheel\n",
      "  running egg_info\n",
      "  writing llama_cpp_python.egg-info/PKG-INFO\n",
      "  writing dependency_links to llama_cpp_python.egg-info/dependency_links.txt\n",
      "  writing requirements to llama_cpp_python.egg-info/requires.txt\n",
      "  writing top-level names to llama_cpp_python.egg-info/top_level.txt\n",
      "  reading manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE.md'\n",
      "  writing manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Running command Preparing metadata (pyproject.toml)\n",
      "  running dist_info\n",
      "  creating /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-modern-metadata-s32zm3hg/llama_cpp_python.egg-info\n",
      "  writing /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-modern-metadata-s32zm3hg/llama_cpp_python.egg-info/PKG-INFO\n",
      "  writing dependency_links to /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-modern-metadata-s32zm3hg/llama_cpp_python.egg-info/dependency_links.txt\n",
      "  writing requirements to /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-modern-metadata-s32zm3hg/llama_cpp_python.egg-info/requires.txt\n",
      "  writing top-level names to /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-modern-metadata-s32zm3hg/llama_cpp_python.egg-info/top_level.txt\n",
      "  writing manifest file '/private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-modern-metadata-s32zm3hg/llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  reading manifest file '/private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-modern-metadata-s32zm3hg/llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE.md'\n",
      "  writing manifest file '/private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-modern-metadata-s32zm3hg/llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  creating '/private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-modern-metadata-s32zm3hg/llama_cpp_python-0.1.78.dist-info'\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Link requires a different Python (3.11.4 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/3a/be/650f9c091ef71cb01d735775d554e068752d3ff63d7943b26316dc401749/numpy-1.21.2.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "  Link requires a different Python (3.11.4 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/5f/d6/ad58ded26556eaeaa8c971e08b6466f17c4ac4d786cd3d800e26ce59cc01/numpy-1.21.3.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "  Link requires a different Python (3.11.4 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/fb/48/b0708ebd7718a8933f0d3937513ef8ef2f4f04529f1f66ca86d873043921/numpy-1.21.4.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "  Link requires a different Python (3.11.4 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/c2/a8/a924a09492bdfee8c2ec3094d0a13f2799800b4fdc9c890738aeeb12c72e/numpy-1.21.5.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "  Link requires a different Python (3.11.4 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/45/b7/de7b8e67f2232c26af57c205aaad29fe17754f793404f59c8a730c7a191a/numpy-1.21.6.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "Collecting numpy==1.23.4\n",
      "  Obtaining dependency information for numpy==1.23.4 from https://files.pythonhosted.org/packages/04/d4/12493d1ed7d6bd5a29016eea021a32011aef266d23a9a4fdefd5ad520eed/numpy-1.23.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading numpy-1.23.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.3 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from llama-cpp-python==0.1.78)\n",
      "  Obtaining dependency information for typing-extensions>=4.5.0 from https://files.pythonhosted.org/packages/01/f3/936e209267d6ef7510322191003885de524fc48d1b43269810cd589ceaf5/typing_extensions-4.11.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.1.78)\n",
      "  Obtaining dependency information for diskcache>=5.6.1 from https://files.pythonhosted.org/packages/3f/27/4570e78fc0bf5ea0ca45eb1de3818a23787af9b390c0b0a0033a1b8236f9/diskcache-5.6.3-py3-none-any.whl.metadata\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Downloading numpy-1.23.4-cp311-cp311-macosx_11_0_arm64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Running command Building wheel for llama-cpp-python (pyproject.toml)\n",
      "\n",
      "\n",
      "  --------------------------------------------------------------------------------\n",
      "  -- Trying 'Ninja' generator\n",
      "  --------------------------------\n",
      "  ---------------------------\n",
      "  ----------------------\n",
      "  -----------------\n",
      "  ------------\n",
      "  -------\n",
      "  --\n",
      "  \u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
      "    Compatibility with CMake < 3.5 will be removed from a future version of\n",
      "    CMake.\n",
      "\n",
      "    Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
      "    CMake that the project does not need compatibility with older versions.\n",
      "\n",
      "  \u001b[0mNot searching for unused variables given on the command line.\n",
      "\n",
      "  -- The C compiler identification is AppleClang 15.0.0.15000309\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - done\n",
      "  -- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/cc - skipped\n",
      "  -- Detecting C compile features\n",
      "  -- Detecting C compile features - done\n",
      "  -- The CXX compiler identification is AppleClang 15.0.0.15000309\n",
      "  -- Detecting CXX compiler ABI info\n",
      "  -- Detecting CXX compiler ABI info - done\n",
      "  -- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/c++ - skipped\n",
      "  -- Detecting CXX compile features\n",
      "  -- Detecting CXX compile features - done\n",
      "  -- Configuring done (4.6s)\n",
      "  -- Generating done (0.0s)\n",
      "  -- Build files have been written to: /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-install-vwmozi4b/llama-cpp-python_b04dc8c3e3a948aeb455010106d74c4c/_cmake_test_compile/build\n",
      "  --\n",
      "  -------\n",
      "  ------------\n",
      "  -----------------\n",
      "  ----------------------\n",
      "  ---------------------------\n",
      "  --------------------------------\n",
      "  -- Trying 'Ninja' generator - success\n",
      "  --------------------------------------------------------------------------------\n",
      "\n",
      "  Configuring Project\n",
      "    Working directory:\n",
      "      /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-install-vwmozi4b/llama-cpp-python_b04dc8c3e3a948aeb455010106d74c4c/_skbuild/macosx-14.0-arm64-3.11/cmake-build\n",
      "    Command:\n",
      "      /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-build-env-64jatfx4/overlay/lib/python3.11/site-packages/cmake/data/bin/cmake /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-install-vwmozi4b/llama-cpp-python_b04dc8c3e3a948aeb455010106d74c4c -G Ninja -DCMAKE_MAKE_PROGRAM:FILEPATH=/private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-build-env-64jatfx4/overlay/lib/python3.11/site-packages/ninja/data/bin/ninja --no-warn-unused-cli -DCMAKE_INSTALL_PREFIX:PATH=/private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-install-vwmozi4b/llama-cpp-python_b04dc8c3e3a948aeb455010106d74c4c/_skbuild/macosx-14.0-arm64-3.11/cmake-install -DPYTHON_VERSION_STRING:STRING=3.11.4 -DSKBUILD:INTERNAL=TRUE -DCMAKE_MODULE_PATH:PATH=/private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-build-env-64jatfx4/overlay/lib/python3.11/site-packages/skbuild/resources/cmake -DPYTHON_EXECUTABLE:PATH=/Users/vishalpatel/anaconda3/bin/python -DPYTHON_INCLUDE_DIR:PATH=/Users/vishalpatel/anaconda3/include/python3.11 -DPYTHON_LIBRARY:PATH=/Users/vishalpatel/anaconda3/lib/libpython3.11.dylib -DPython_EXECUTABLE:PATH=/Users/vishalpatel/anaconda3/bin/python -DPython_ROOT_DIR:PATH=/Users/vishalpatel/anaconda3 -DPython_FIND_REGISTRY:STRING=NEVER -DPython_INCLUDE_DIR:PATH=/Users/vishalpatel/anaconda3/include/python3.11 -DPython3_EXECUTABLE:PATH=/Users/vishalpatel/anaconda3/bin/python -DPython3_ROOT_DIR:PATH=/Users/vishalpatel/anaconda3 -DPython3_FIND_REGISTRY:STRING=NEVER -DPython3_INCLUDE_DIR:PATH=/Users/vishalpatel/anaconda3/include/python3.11 -DCMAKE_MAKE_PROGRAM:FILEPATH=/private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-build-env-64jatfx4/overlay/lib/python3.11/site-packages/ninja/data/bin/ninja -DLLAMA_CUBLAS=on -DCMAKE_OSX_DEPLOYMENT_TARGET:STRING=14.0 -DCMAKE_OSX_ARCHITECTURES:STRING=arm64 -DCMAKE_BUILD_TYPE:STRING=Release -DLLAMA_CUBLAS=on\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Not searching for unused variables given on the command line.\n",
      "  -- The C compiler identification is AppleClang 15.0.0.15000309\n",
      "  -- The CXX compiler identification is AppleClang 15.0.0.15000309\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - done\n",
      "  -- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/cc - skipped\n",
      "  -- Detecting C compile features\n",
      "  -- Detecting C compile features - done\n",
      "  -- Detecting CXX compiler ABI info\n",
      "  -- Detecting CXX compiler ABI info - done\n",
      "  -- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/c++ - skipped\n",
      "  -- Detecting CXX compile features\n",
      "  -- Detecting CXX compile features - done\n",
      "  -- Found Git: /opt/homebrew/bin/git (found version \"2.44.0\")\n",
      "  fatal: not a git repository (or any of the parent directories): .git\n",
      "  fatal: not a git repository (or any of the parent directories): .git\n",
      "  \u001b[33mCMake Warning at vendor/llama.cpp/CMakeLists.txt:117 (message):\n",
      "    Git repository not found; to enable automatic generation of build info,\n",
      "    make sure Git is installed and the project is a Git repository.\n",
      "\n",
      "  \u001b[0m\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "  -- Found Threads: TRUE\n",
      "  -- Accelerate framework found\n",
      "  -- Could not find nvcc, please set CUDAToolkit_ROOT.\n",
      "  \u001b[33mCMake Warning at vendor/llama.cpp/CMakeLists.txt:291 (message):\n",
      "    cuBLAS not found\n",
      "\n",
      "  \u001b[0m\n",
      "  -- CMAKE_SYSTEM_PROCESSOR: arm64\n",
      "  -- ARM detected\n",
      "  -- Configuring done (0.4s)\n",
      "  -- Generating done (0.0s)\n",
      "  -- Build files have been written to: /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-install-vwmozi4b/llama-cpp-python_b04dc8c3e3a948aeb455010106d74c4c/_skbuild/macosx-14.0-arm64-3.11/cmake-build\n",
      "  [1/8] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o\n",
      "  [2/8] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/k_quants.c.o\n",
      "  [3/8] Building CXX object vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o\n",
      "  [4/8] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o\n",
      "  /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-install-vwmozi4b/llama-cpp-python_b04dc8c3e3a948aeb455010106d74c4c/vendor/llama.cpp/ggml.c:10698:17: warning: 'cblas_sgemm' is deprecated: first deprecated in macOS 13.3 - An updated CBLAS interface supporting ILP64 is available.  Please compile with -DACCELERATE_NEW_LAPACK to access the new headers and -DACCELERATE_LAPACK_ILP64 for ILP64 support. [-Wdeprecated-declarations]\n",
      "                  cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasTrans,\n",
      "                  ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX14.4.sdk/System/Library/Frameworks/vecLib.framework/Headers/cblas.h:610:6: note: 'cblas_sgemm' has been explicitly marked deprecated here\n",
      "  void cblas_sgemm(const enum CBLAS_ORDER __Order,\n",
      "       ^\n",
      "  1 warning generated.\n",
      "  [5/8] Linking C shared library vendor/llama.cpp/libggml_shared.dylib\n",
      "  [6/8] Linking CXX shared library vendor/llama.cpp/libllama.dylib\n",
      "  [7/8] Linking C static library vendor/llama.cpp/libggml_static.a\n",
      "  [7/8] Install the project...\n",
      "  -- Install configuration: \"Release\"\n",
      "  -- Installing: /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-install-vwmozi4b/llama-cpp-python_b04dc8c3e3a948aeb455010106d74c4c/_skbuild/macosx-14.0-arm64-3.11/cmake-install/lib/libggml_shared.dylib\n",
      "  -- Installing: /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-install-vwmozi4b/llama-cpp-python_b04dc8c3e3a948aeb455010106d74c4c/_skbuild/macosx-14.0-arm64-3.11/cmake-install/lib/libllama.dylib\n",
      "  -- Installing: /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-install-vwmozi4b/llama-cpp-python_b04dc8c3e3a948aeb455010106d74c4c/_skbuild/macosx-14.0-arm64-3.11/cmake-install/bin/convert.py\n",
      "  -- Installing: /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-install-vwmozi4b/llama-cpp-python_b04dc8c3e3a948aeb455010106d74c4c/_skbuild/macosx-14.0-arm64-3.11/cmake-install/bin/convert-lora-to-ggml.py\n",
      "  -- Installing: /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-install-vwmozi4b/llama-cpp-python_b04dc8c3e3a948aeb455010106d74c4c/_skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/libllama.dylib\n",
      "\n",
      "  copying llama_cpp/llama_types.py -> _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/llama_types.py\n",
      "  copying llama_cpp/__init__.py -> _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/__init__.py\n",
      "  copying llama_cpp/llama_cpp.py -> _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/llama_cpp.py\n",
      "  copying llama_cpp/llama.py -> _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/llama.py\n",
      "  copying llama_cpp/utils.py -> _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/utils.py\n",
      "  copying llama_cpp/llama_grammar.py -> _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/llama_grammar.py\n",
      "  creating directory _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/server\n",
      "  copying llama_cpp/server/__init__.py -> _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/server/__init__.py\n",
      "  copying llama_cpp/server/app.py -> _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/server/app.py\n",
      "  copying llama_cpp/server/__main__.py -> _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/server/__main__.py\n",
      "  copying /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-install-vwmozi4b/llama-cpp-python_b04dc8c3e3a948aeb455010106d74c4c/llama_cpp/py.typed -> _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/py.typed\n",
      "\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311\n",
      "  creating _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/llama_types.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/__init__.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/llama_cpp.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/llama.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/utils.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/llama_grammar.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  creating _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/server\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/server/__init__.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/server\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/server/app.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/server\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/server/__main__.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/server\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/py.typed -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/libllama.dylib -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/llama_types.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/__init__.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/llama_cpp.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/llama.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/utils.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/llama_grammar.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/server/__init__.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/server\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/server/app.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/server\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/llama_cpp/server/__main__.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/server\n",
      "  copied 9 files\n",
      "  running build_ext\n",
      "  installing to _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel\n",
      "  running install\n",
      "  running install_lib\n",
      "  creating _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64\n",
      "  creating _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel\n",
      "  creating _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/llama_types.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/__init__.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/llama_cpp.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp\n",
      "  creating _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp/server\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/server/__init__.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp/server\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/server/app.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp/server\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/server/__main__.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp/server\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/libllama.dylib -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/llama.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/utils.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/llama_grammar.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/setuptools/lib.macosx-14.0-arm64-cpython-311/llama_cpp/py.typed -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp\n",
      "  copied 11 files\n",
      "  running install_data\n",
      "  creating _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp_python-0.1.78.data\n",
      "  creating _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp_python-0.1.78.data/data\n",
      "  creating _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/lib/libggml_shared.dylib -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/lib/libllama.dylib -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
      "  creating _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/bin/convert.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
      "  copying _skbuild/macosx-14.0-arm64-3.11/cmake-install/bin/convert-lora-to-ggml.py -> _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
      "  running install_egg_info\n",
      "  running egg_info\n",
      "  writing llama_cpp_python.egg-info/PKG-INFO\n",
      "  writing dependency_links to llama_cpp_python.egg-info/dependency_links.txt\n",
      "  writing requirements to llama_cpp_python.egg-info/requires.txt\n",
      "  writing top-level names to llama_cpp_python.egg-info/top_level.txt\n",
      "  reading manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE.md'\n",
      "  writing manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  Copying llama_cpp_python.egg-info to _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp_python-0.1.78-py3.11.egg-info\n",
      "  running install_scripts\n",
      "  copied 0 files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  creating _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel/llama_cpp_python-0.1.78.dist-info/WHEEL\n",
      "  creating '/private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-wheel-3ca92eba/.tmp-8bg0pft1/llama_cpp_python-0.1.78-cp311-cp311-macosx_14_0_arm64.whl' and adding '_skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel' to it\n",
      "  adding 'llama_cpp/__init__.py'\n",
      "  adding 'llama_cpp/libllama.dylib'\n",
      "  adding 'llama_cpp/llama.py'\n",
      "  adding 'llama_cpp/llama_cpp.py'\n",
      "  adding 'llama_cpp/llama_grammar.py'\n",
      "  adding 'llama_cpp/llama_types.py'\n",
      "  adding 'llama_cpp/py.typed'\n",
      "  adding 'llama_cpp/utils.py'\n",
      "  adding 'llama_cpp/server/__init__.py'\n",
      "  adding 'llama_cpp/server/__main__.py'\n",
      "  adding 'llama_cpp/server/app.py'\n",
      "  adding 'llama_cpp_python-0.1.78.data/data/bin/convert-lora-to-ggml.py'\n",
      "  adding 'llama_cpp_python-0.1.78.data/data/bin/convert.py'\n",
      "  adding 'llama_cpp_python-0.1.78.data/data/lib/libggml_shared.dylib'\n",
      "  adding 'llama_cpp_python-0.1.78.data/data/lib/libllama.dylib'\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/LICENSE.md'\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/METADATA'\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/WHEEL'\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/top_level.txt'\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/RECORD'\n",
      "  removing _skbuild/macosx-14.0-arm64-3.11/setuptools/bdist.macosx-14.0-arm64/wheel\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.78-cp311-cp311-macosx_14_0_arm64.whl size=596686 sha256=6ad7fa674480ae27c08317dd536d534d2ea0b9effb787e244f67618993208768\n",
      "  Stored in directory: /private/var/folders/kt/_wys5q9j4f5cxnwphmf7mxjh0000gn/T/pip-ephem-wheel-cache-pgzn_0e1/wheels/18/69/ad/9b1cec6b18fe403616b8cfbf10021d1939cba077cee285c5c3\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: typing-extensions, numpy, diskcache, llama-cpp-python\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Removing file or directory /Users/vishalpatel/anaconda3/lib/python3.11/site-packages/__pycache__/typing_extensions.cpython-311.pyc\n",
      "      Removing file or directory /Users/vishalpatel/anaconda3/lib/python3.11/site-packages/typing_extensions-4.11.0.dist-info/\n",
      "      Removing file or directory /Users/vishalpatel/anaconda3/lib/python3.11/site-packages/typing_extensions.py\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Removing file or directory /Users/vishalpatel/anaconda3/bin/f2py\n",
      "      Removing file or directory /Users/vishalpatel/anaconda3/bin/f2py3\n",
      "      Removing file or directory /Users/vishalpatel/anaconda3/bin/f2py3.11\n",
      "      Removing file or directory /Users/vishalpatel/anaconda3/lib/python3.11/site-packages/numpy-1.24.3.dist-info/\n",
      "      Removing file or directory /Users/vishalpatel/anaconda3/lib/python3.11/site-packages/numpy/\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  changing mode of /Users/vishalpatel/anaconda3/bin/f2py to 755\n",
      "  changing mode of /Users/vishalpatel/anaconda3/bin/f2py3 to 755\n",
      "  changing mode of /Users/vishalpatel/anaconda3/bin/f2py3.11 to 755\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "pandas-profiling 3.2.0 requires visions[type_image_path]==0.7.4, but you have visions 0.7.5 which is incompatible.\n",
      "onnxruntime 1.17.3 requires numpy>=1.24.2, but you have numpy 1.23.4 which is incompatible.\n",
      "tensorflow 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.1.78 numpy-1.23.4 typing-extensions-4.11.0\n",
      "Requirement already satisfied: huggingface_hub in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (0.15.1)\n",
      "Requirement already satisfied: filelock in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (3.9.0)\n",
      "Requirement already satisfied: fsspec in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (2023.4.0)\n",
      "Requirement already satisfied: requests in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub) (2023.7.22)\n",
      "Requirement already satisfied: llama-cpp-python==0.1.78 in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (0.1.78)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from llama-cpp-python==0.1.78) (4.11.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from llama-cpp-python==0.1.78) (1.23.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (from llama-cpp-python==0.1.78) (5.6.3)\n",
      "Requirement already satisfied: numpy==1.23.4 in /Users/vishalpatel/anaconda3/lib/python3.11/site-packages (1.23.4)\n"
     ]
    }
   ],
   "source": [
    "# GPU llama-cpp-python\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 numpy==1.23.4 --force-reinstall --upgrade --no-cache-dir --verbose\n",
    "!pip install huggingface_hub # we use hugginge face plateform to use LLama model.\n",
    "!pip install llama-cpp-python==0.1.78\n",
    "!pip install numpy==1.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba731fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
    "model_basename = \"llama-2-13b-chat.ggmlv3.q5_1.bin\" # the model is in bin format\n",
    "# llama-2-13b-chat.ggmlv3.q5_1.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d546de",
   "metadata": {},
   "source": [
    "# 2: Import All the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "870939b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb8e4a9",
   "metadata": {},
   "source": [
    "# 3. Download the model in our system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c8cb20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16404a27f67b45eaa7445ffcc099c374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)chat.ggmlv3.q5_1.bin:   0%|          | 0.00/9.76G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eee8de",
   "metadata": {},
   "source": [
    "# 4. Load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f7355c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/vishalpatel/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_head_kv  = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 5.0e-06\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 9 (mostly Q5_1)\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.11 MB\n",
      "llama_model_load_internal: mem required  = 9311.07 MB (+  400.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  400.00 MB\n",
      "llama_new_context_with_model: compute buffer total size =   75.35 MB\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "lcpp_llm = None\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2, # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98760972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the number of layers in GPU\n",
    "lcpp_llm.params.n_gpu_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb7057d",
   "metadata": {},
   "source": [
    "# 5: Create a Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9230e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a linear regression code\"\n",
    "prompt_template=f'''SYSTEM: You are a helpful, respectful and honest assistant. Always answer as helpfully.\n",
    "\n",
    "USER: {prompt}\n",
    "\n",
    "ASSISTANT:\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e150cad",
   "metadata": {},
   "source": [
    "# 6 .: Generating the Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f36588",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=lcpp_llm(prompt=prompt_template, max_tokens=256, temperature=0.5, top_p=0.95,\n",
    "                  repeat_penalty=1.2, top_k=150,\n",
    "                  echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b96fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3766c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c386f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
