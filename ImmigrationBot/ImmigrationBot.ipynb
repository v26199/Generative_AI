{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22027,"status":"ok","timestamp":1692161127058,"user":{"displayName":"Vishal Patel","userId":"02637482279999814982"},"user_tz":240},"id":"QcnNL5kLTFta","outputId":"00a24989-9992-4eaa-b134-6e18f8d0a342"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["#Mounting Google drive.\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":81013,"status":"ok","timestamp":1692161263691,"user":{"displayName":"Vishal Patel","userId":"02637482279999814982"},"user_tz":240},"id":"WQRJF3DmY4op","outputId":"efe6de91-c7ff-431c-c912-b4300bb3cf05"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Collecting keras\n","  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Collecting tensorflow\n","  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n","Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Collecting tensorboard<2.14,>=2.13 (from tensorflow)\n","  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow)\n","  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow)\n","  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.6)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n","Installing collected packages: typing-extensions, tensorflow-estimator, keras, tensorboard, tensorflow\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.7.1\n","    Uninstalling typing_extensions-4.7.1:\n","      Successfully uninstalled typing_extensions-4.7.1\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.12.0\n","    Uninstalling tensorflow-estimator-2.12.0:\n","      Successfully uninstalled tensorflow-estimator-2.12.0\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.12.0\n","    Uninstalling keras-2.12.0:\n","      Successfully uninstalled keras-2.12.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.3\n","    Uninstalling tensorboard-2.12.3:\n","      Successfully uninstalled tensorboard-2.12.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.12.0\n","    Uninstalling tensorflow-2.12.0:\n","      Successfully uninstalled tensorflow-2.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pydantic 2.1.1 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n","pydantic-core 2.4.0 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["keras","tensorboard","tensorflow"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n","Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyPDF2\n","Successfully installed PyPDF2-3.0.1\n","Collecting python-docx\n","  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n","Building wheels for collected packages: python-docx\n","  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184487 sha256=fa7cdf435e309d97731dd12484626fdfe86e654b890c92d6229e470024aabfa5\n","  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n","Successfully built python-docx\n","Installing collected packages: python-docx\n","Successfully installed python-docx-0.8.11\n","Collecting python-magic\n","  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n","Installing collected packages: python-magic\n","Successfully installed python-magic-0.4.27\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["#installing all the required packages.\n","\n","!pip install --upgrade keras tensorflow\n","!pip install transformers\n","!pip install -U PyPDF2\n","!pip install python-docx\n","!pip install python-magic\n","!pip install transformers torch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2nzS8ynksT89"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692161127059,"user":{"displayName":"Vishal Patel","userId":"02637482279999814982"},"user_tz":240},"id":"lv3w3FP3UNFY"},"outputs":[],"source":["# Data loading and preprocesing(clearing noice and removeing unwanted data(like special symbol, extra spaces, numbers))\n","import pandas as pd\n","import numpy as np\n","import re\n","from PyPDF2 import PdfReader\n","import os\n","import docx\n","import magic\n","import matplotlib.pyplot as plt\n","\n","\n","BASE_PATH = \"/content/gdrive/MyDrive/Final/Immigration/data.txt\"\n","OUTPUT_FILE = \"/content/gdrive/MyDrive/Final/Immigration/data.txt\"\n","\n","class DocumentManager:\n","\n","    def __init__(self, base_path):\n","        \"\"\"Initialize the DocumentManager with a base path.\"\"\"\n","        self.base_path = base_path\n","\n","    def detect_file_type(self, file_path):\n","        \"\"\"Detect file type based on its content using python-magic and file extension.\"\"\"\n","\n","        # First, check based on file extension\n","        file_extension = os.path.splitext(file_path)[1].lower()\n","\n","        if file_extension == '.pdf':\n","            return \"application/pdf\"\n","        elif file_extension == '.docx':\n","            return \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n","        elif file_extension == '.txt':\n","            return \"text/plain\"\n","\n","        # If file extension is not recognized or matches, check using python-magic\n","        return magic.from_file(file_path, mime=True)\n","\n","    def read_pdf(self, file_path):\n","        \"\"\"Read a PDF file.\"\"\"\n","        try:\n","            with open(file_path, \"rb\") as file:\n","                pdf_reader = PdfReader(file)\n","                text = \"\".join(page.extract_text() for page in pdf_reader.pages)\n","            return text\n","        except Exception as e:\n","            print(f\"Error reading PDF {file_path}: {e}\")\n","            raise e\n","\n","    def read_word(self, file_path):\n","        \"\"\"Read a DOCX file.\"\"\"\n","        try:\n","            doc = docx.Document(file_path)\n","            text = \"\\n\".join(paragraph.text for paragraph in doc.paragraphs)\n","            return text\n","        except Exception as e:\n","            print(f\"Error reading DOCX {file_path}: {e}\")\n","            raise e\n","\n","    def read_txt(self, file_path):\n","        \"\"\"Read a TXT file.\"\"\"\n","        try:\n","            with open(file_path, \"r\") as file:\n","                return file.read()\n","        except Exception as e:\n","            print(f\"Error reading TXT {file_path}: {e}\")\n","            raise e\n","\n","    def compile_documents(self):\n","        \"\"\"Compile documents from the base path into a single text file.\"\"\"\n","        # Get file type\n","        file_type = self.detect_file_type(self.base_path)\n","\n","        # Based on file type, read the content\n","        if file_type == \"application/pdf\":\n","            content = self.read_pdf(self.base_path)\n","        elif file_type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n","            content = self.read_word(self.base_path)\n","        elif file_type == \"text/plain\":\n","            content = self.read_txt(self.base_path)\n","        else:\n","            raise ValueError(f\"Unsupported file type: {file_type}\")\n","\n","        # Clean and format the content\n","        formatted_content = self.clean_and_format_text(content)\n","\n","        return formatted_content\n","\n","    def clean_and_format_text(self, text):\n","        # Split the text into lines\n","        lines = text.splitlines()\n","\n","        # Count lines before cleaning\n","        self.before_count = len(lines)\n","\n","        # Filter out the empty or whitespace-only lines\n","        cleaned_lines = [line for line in lines if line.strip() != \"\"]\n","\n","        # Count lines after cleaning\n","        self.after_count = len(cleaned_lines)\n","\n","        # Join the cleaned lines and ensure no consecutive newlines\n","        formatted_text = \"\\n\".join(cleaned_lines)\n","        formatted_text = re.sub(r'\\n+', '\\n', formatted_text).strip()\n","\n","        return formatted_text\n","\n","    def save_to_file(self, output_path):\n","        \"\"\"Save the compiled documents to a specific file.\"\"\"\n","        text_data = self.compile_documents()\n","        try:\n","            with open(output_path, \"w\") as f:\n","                f.write(text_data)\n","        except Exception as e:\n","            print(f\"Error saving to file {output_path}: {e}\")\n","            raise e\n","\n","    def plot_results(self):\n","        plt.bar(['Before Cleaning', 'After Cleaning'], [self.before_count, self.after_count],color=['red', 'blue'])\n","        plt.title('Number of Records Before and After Cleaning')\n","        plt.ylabel('Number of Records')\n","        plt.show()\n","\n","if __name__ == '__main__':\n","    doc_manager = DocumentManager(BASE_PATH)\n","    doc_manager.save_to_file(OUTPUT_FILE)\n","    print(f\"Total Records Before Cleaning: {doc_manager.before_count}\")\n","    print(f\"Total Records After Cleaning: {doc_manager.after_count}\")\n","    doc_manager.plot_results()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692161127059,"user":{"displayName":"Vishal Patel","userId":"02637482279999814982"},"user_tz":240},"id":"j-U4nGFxzJCY"},"outputs":[],"source":["\"\"\"\n","Chatbot Dataset Cleaner\n","Semantic Filtering of User-Bot Conversations\n","\"\"\"\n","import json\n","import re\n","import numpy as np\n","import nltk\n","import torch\n","from sentence_transformers import SentenceTransformer, util\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","BASE_PATH = \"/content/gdrive/MyDrive/Final/Immigration/data.txt\"\n","OUTPUT_FILE = \"/content/gdrive/MyDrive/Final/Immigration/data.txt\"\n","\n","class DataCleaner:\n","    @staticmethod\n","    def is_valid_pattern(pattern):\n","        \"\"\"Check if the pattern contains at least one word.\"\"\"\n","        return len(pattern.strip()) > 0\n","\n","    @staticmethod\n","    def is_valid_response(response):\n","        \"\"\"Check if the response contains at least one word.\"\"\"\n","        return len(response.strip()) > 0\n","\n","    @staticmethod\n","    def batch_is_semantically_relevant(batch_patterns, batch_responses):\n","        \"\"\"Determine if batches of patterns and responses are semantically relevant.\"\"\"\n","        model = SentenceTransformer('bert-base-nli-mean-tokens')\n","        pattern_embeddings = model.encode(batch_patterns)\n","        response_embeddings = model.encode(batch_responses)\n","        similarity_scores = util.pytorch_cos_sim(pattern_embeddings, response_embeddings)\n","        similarity_threshold = 0.6\n","        return (similarity_scores >= similarity_threshold).any(dim=1).tolist()\n","\n","    @classmethod\n","    def clean_data(cls, dataset_path):\n","        \"\"\"Process and clean the dataset by filtering semantically irrelevant and duplicate pairs.\"\"\"\n","        with open(dataset_path, 'r') as file:\n","            lines = file.readlines()\n","            patterns = [lines[i+1].strip() for i in range(0, len(lines), 2)]\n","            responses = [lines[i].strip() for i in range(0, len(lines), 2)]\n","\n","        # Validate patterns and responses\n","        patterns = [pattern.split(': ')[1] for pattern in patterns if cls.is_valid_pattern(pattern)]\n","        responses = [response.split(': ')[1] for response in responses if cls.is_valid_response(response)]\n","\n","        # Remove duplicates\n","        unique_pairs = list(set(zip(patterns, responses)))\n","        patterns = [item[0] for item in unique_pairs]\n","        responses = [item[1] for item in unique_pairs]\n","\n","        filtered_patterns, filtered_responses = [], []\n","        for pattern, response in zip(patterns, responses):\n","            is_relevant = cls.batch_is_semantically_relevant([pattern], [response])\n","            if is_relevant[0]:\n","                filtered_patterns.append(pattern)\n","                filtered_responses.append(response)\n","\n","        # Convert data to alternate user-bot format and save\n","        cleaned_data = []\n","        for p, r in zip(filtered_patterns, filtered_responses):\n","            cleaned_data.append(f\"User: {p}\\nBot: {r}\\n\")\n","\n","        with open(\"/content/gdrive/MyDrive/Final/Immigration/data.txt\", 'w') as outfile:\n","            outfile.writelines(cleaned_data)\n","\n","        return 'train.txt'\n","\n","    @staticmethod\n","    def compare_data(original_file, cleaned_file):\n","        \"\"\"Compare the number of patterns and responses between original and cleaned data files.\"\"\"\n","        with open(original_file, 'r') as orig_file:\n","            original_lines = orig_file.readlines()\n","\n","        with open(cleaned_file, 'r') as cleaned_file:\n","            cleaned_lines = cleaned_file.readlines()\n","\n","        print(\"Number of lines in original file:\", len(original_lines))\n","        print(\"Number of lines in cleaned file:\", len(cleaned_lines))\n","\n","\n","def main():\n","    dataset_path = \"/content/gdrive/MyDrive/Project/Chatbot/traindata.txt\"\n","    cleaned_file = DataCleaner.clean_data(dataset_path)\n","    DataCleaner.compare_data(dataset_path, cleaned_file)\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1692161127060,"user":{"displayName":"Vishal Patel","userId":"02637482279999814982"},"user_tz":240},"id":"Jz-61f3UMQom"},"outputs":[],"source":["# TEXT DATA PREPROCESING:\n","import re\n","import pickle\n","import tensorflow as tf\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","\n","\n","# Check for GPU availability\n","if tf.test.gpu_device_name():\n","    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n","else:\n","    print(\"Please install GPU version of TensorFlow\")\n","\n","class ChatbotDataPreprocessor:\n","    def __init__(self, base_path, filepath, max_vocab=50000, max_seq_len=200):\n","        self.filepath = filepath\n","        self.max_vocab = max_vocab\n","        self.max_seq_len = max_seq_len\n","        self.base_path = base_path\n","\n","        self.TOKENIZER_PATH = self.base_path + \"tokenizer.pkl\"\n","        self.SEQUENCES_PATH = self.base_path + \"preprocessed_data.pkl\"\n","\n","        # Initialize tokenizer with special tokens and filters\n","        self.tokenizer = Tokenizer(num_words=self.max_vocab, oov_token='<OOV>', filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n","        self.questions = []\n","        self.answers = []\n","\n","    # Load dialogue data from file\n","    def load_data(self):\n","        try:\n","            with open(self.filepath, 'r') as file:\n","                lines = file.readlines()\n","            if not lines:\n","                print(\"Warning: Loaded data is empty.\")\n","                return []\n","            return lines\n","        except Exception as e:\n","            print(f\"Error loading data from {self.filepath}: {e}\")\n","            return []\n","\n","    # Basic text cleaning\n","    def clean_text(self, text):\n","        text = text.lower().strip()\n","        text = re.sub(r\"[^a-z0-9'\\s]+\", \" \", text)\n","        return text\n","\n","    # Extract question-answer pairs from loaded data\n","    def create_dialogue_pairs(self, lines):\n","        questions_temp = []\n","        answers_temp = []\n","\n","        for index, line in enumerate(lines):\n","            if \"User:\" in line:\n","                questions_temp.append(self.clean_text(line.replace(\"User:\", \"\")))\n","            elif \"Bot:\" in line:\n","                answers_temp.append(self.clean_text(line.replace(\"Bot:\", \"\")))\n","\n","        # Ensure that the number of questions and answers match\n","        min_len = min(len(questions_temp), len(answers_temp))\n","        self.questions = questions_temp[:min_len]\n","        self.answers = answers_temp[:min_len]\n","\n","        if len(questions_temp) != len(answers_temp):\n","            print(\"Warning: Number of questions and answers don't match! Truncated to match lengths.\")\n","\n","\n","    # Convert text data to padded numeric sequences\n","    def tokenize_and_pad(self, texts):\n","        sequences = self.tokenizer.texts_to_sequences(texts)\n","        padded = pad_sequences(sequences, maxlen=self.max_seq_len, padding='post')\n","        return padded\n","\n","    # Save tokenizer to file\n","    def save_tokenizer(self, filename):\n","        try:\n","            with open(filename, 'wb') as file:\n","                pickle.dump(self.tokenizer, file)\n","            print(f\"Tokenizer saved successfully to {filename}.\")\n","        except Exception as e:\n","            print(f\"Error saving tokenizer to {filename}: {e}\")\n","\n","    # Save preprocessed data to file\n","    def save_sequences(self, filename, train_q, test_q, train_a, test_a):\n","        try:\n","            with open(filename, 'wb') as file:\n","                pickle.dump({\n","                    'train_questions': train_q,\n","                    'test_questions': test_q,\n","                    'train_answers': train_a,\n","                    'test_answers': test_a,\n","                    'tokenizer': self.tokenizer\n","                }, file)\n","            print(f\"Sequences saved successfully to {filename}.\")\n","        except Exception as e:\n","            print(f\"Error saving sequences to {filename}: {e}\")\n","\n","    # Main preprocessing function\n","    def preprocess(self):\n","        lines = self.load_data()\n","        if not lines:\n","            return\n","        self.create_dialogue_pairs(lines)\n","        self.tokenizer.fit_on_texts(self.questions + self.answers)\n","\n","        # Assign index 0 to the padding token after fitting the tokenizer on texts\n","        self.tokenizer.word_index['<pad>'] = 0\n","\n","        train_q, test_q, train_a, test_a = train_test_split(self.questions, self.answers, test_size=0.2)\n","\n","        train_q = self.tokenize_and_pad(train_q)\n","        test_q = self.tokenize_and_pad(test_q)\n","        train_a = self.tokenize_and_pad(train_a)\n","        test_a = self.tokenize_and_pad(test_a)\n","\n","        self.save_tokenizer(self.TOKENIZER_PATH)\n","        self.save_sequences(self.SEQUENCES_PATH, train_q, test_q, train_a, test_a)\n","\n","\n","\n","if __name__ == \"__main__\":\n","    BASE_PATH = \"/content/gdrive/MyDrive/Final/Immigration/\"\n","    FILE_PATH = BASE_PATH + \"data.txt\"\n","\n","    preprocessor = ChatbotDataPreprocessor(BASE_PATH, filepath=FILE_PATH)\n","    preprocessor.preprocess()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692161127060,"user":{"displayName":"Vishal Patel","userId":"02637482279999814982"},"user_tz":240},"id":"2ayeAMM5MQrN"},"outputs":[],"source":["#check the result from above preprocessing.\n","\n","BASE_PATH = \"/content/gdrive/MyDrive/Final/Immigration/\"\n","with open(BASE_PATH + \"preprocessed_data.pkl\", \"rb\") as file:\n","    preprocessed_data = pickle.load(file)\n","\n","print(preprocessed_data.keys())\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1545,"status":"ok","timestamp":1692161128601,"user":{"displayName":"Vishal Patel","userId":"02637482279999814982"},"user_tz":240},"id":"_BIDqUu7m3PV","outputId":"0c5f9911-1f79-46fe-dd3d-5f6f2a64b7c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/Final/Immigration/ exists.\n","Files inside the directory:\n","data.txt\n","requirements.txt.gdoc\n","tokenizer.pkl\n","preprocessed_data.pkl\n","GPT\n","chatbot_model_best.pth\n","chatbot_model_final.pth\n","HotelAssist.ipynb\n"]}],"source":["#checking the fiels and basepath access\n","import os\n","\n","BASE_PATH = \"/content/gdrive/MyDrive/Final/Immigration/\"\n","\n","# Check if BASE_PATH exists\n","if not os.path.exists(BASE_PATH):\n","    raise ValueError(f\"The directory {BASE_PATH} does not exist!\")\n","else:\n","    print(f\"{BASE_PATH} exists.\")\n","    # List and print existing files inside BASE_PATH\n","    files_in_directory = os.listdir(BASE_PATH)\n","    if files_in_directory:\n","        print(\"Files inside the directory:\")\n","        for file in files_in_directory:\n","            print(file)\n","    else:\n","        print(\"The directory is empty.\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1692161128602,"user":{"displayName":"Vishal Patel","userId":"02637482279999814982"},"user_tz":240},"id":"Mj73oNhPoE_P"},"outputs":[],"source":["# !pip freeze > requirements.txt\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1692161128602,"user":{"displayName":"Vishal Patel","userId":"02637482279999814982"},"user_tz":240},"id":"RA48lWrnbG80"},"outputs":[],"source":["# IMPORTS\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pickle\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from keras.callbacks import EarlyStopping\n","from torch.utils.data import random_split\n","import numpy as np\n","\n","# BASE CONFIGURATIONS\n","BASE_PATH = \"/content/gdrive/MyDrive/Final/Immigration/\"\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# ENCODER\n","class Encoder(nn.Module):\n","    \"\"\"Encoder module for the Seq2Seq model.\"\"\"\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, bidirectional=True)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src):\n","        embedded = self.dropout(self.embedding(src))\n","        outputs, (hidden, cell) = self.rnn(embedded)\n","        return hidden, cell\n","\n","# DECODER\n","class Decoder(nn.Module):\n","    \"\"\"Decoder module for the Seq2Seq model.\"\"\"\n","    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        self.output_dim = output_dim\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim, hid_dim * 2, n_layers, dropout=dropout)\n","        self.fc_out = nn.Linear(hid_dim * 2, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, input, hidden, cell):\n","        input = input.unsqueeze(0)\n","        embedded = self.dropout(self.embedding(input))\n","        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n","        prediction = self.fc_out(output.squeeze(0))\n","        return prediction, hidden, cell\n","\n","# SEQ2SEQ MODEL\n","class Seq2Seq(nn.Module):\n","    \"\"\"Main Seq2Seq model integrating the Encoder and Decoder.\"\"\"\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n","        trg_len = trg.shape[0]\n","        batch_size = trg.shape[1]\n","        trg_vocab_size = self.decoder.output_dim\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        encoder_hidden, encoder_cell = self.encoder(src)\n","\n","        if self.encoder.rnn.bidirectional:\n","            hidden = torch.cat((encoder_hidden[0:encoder_hidden.size(0):2],\n","                                encoder_hidden[1:encoder_hidden.size(0):2]), dim=2)\n","            cell = torch.cat((encoder_cell[0:encoder_cell.size(0):2],\n","                              encoder_cell[1:encoder_cell.size(0):2]), dim=2)\n","        else:\n","            hidden, cell = encoder_hidden, encoder_cell\n","\n","        input = trg[0]\n","\n","        for t in range(1, trg_len):\n","            output, hidden, cell = self.decoder(input, hidden, cell)\n","            outputs[t] = output\n","            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n","            top1 = output.argmax(1)\n","            input = trg[t] if teacher_force else top1\n","\n","        return outputs\n","\n","# CHATBOT TRAINER\n","class ChatbotTrainer:\n","    def __init__(self, data_path,tokenizer):\n","        self.data_path = data_path\n","        with open(data_path, \"rb\") as file:\n","            preprocessed_data = pickle.load(file)\n","        # self.tokenizer = preprocessed_data['tokenizer']\n","        self.tokenizer = tokenizer\n","        self.questions = preprocessed_data['train_questions']\n","        self.answers = preprocessed_data['train_answers']\n","        self.input_dim = len(self.tokenizer.word_index) + 1\n","        self.output_dim = len(self.tokenizer.word_index) + 1\n","        self.train_losses = []\n","        self.val_losses = []\n","        self.train_accuracies = []\n","        self.val_accuracies = []\n","\n","    @staticmethod\n","    def _accuracy(preds, y):\n","        \"\"\"Returns accuracy per batch.\"\"\"\n","        _, predictions = torch.max(preds, 1)\n","        correct = (predictions == y).float()\n","        acc = correct.sum() / len(correct)\n","        return acc\n","\n","    @staticmethod\n","    def _collate_fn(data):\n","        data.sort(key=lambda x: len(x[0]), reverse=True)\n","        src_seqs, trg_seqs = zip(*data)\n","        src_seqs = [torch.Tensor(s) for s in src_seqs]\n","        trg_seqs = [torch.Tensor(t) for t in trg_seqs]\n","        src_lengths = [len(s) for s in src_seqs]\n","        PAD_IDX = tokenizer.word_index['<pad>']  # Using <pad> token for padding\n","        # PAD_IDX = self.tokenizer.word_index['<pad>']\n","        src_padded = pad_sequence(src_seqs, padding_value=PAD_IDX, batch_first=True)\n","        trg_lengths = [len(t) for t in trg_seqs]\n","        trg_padded = pad_sequence(trg_seqs, padding_value=PAD_IDX, batch_first=True)\n","        return src_padded, src_lengths, trg_padded, trg_lengths\n","\n","    def _train_epoch(self, model, dataloader, optimizer, criterion, clip, teacher_forcing_ratio):\n","        model.train()\n","        epoch_loss = 0\n","        epoch_acc = 0\n","        for i, (src, _, trg, _) in enumerate(dataloader):\n","            src, trg = src.long().to(DEVICE), trg.long().to(DEVICE)\n","            optimizer.zero_grad()\n","            output = model(src, trg, teacher_forcing_ratio)\n","            output_dim = output.shape[-1]\n","            output = output[1:].reshape(-1, output_dim)\n","            trg = trg[1:].reshape(-1)\n","            loss = criterion(output, trg)\n","            acc = self._accuracy(output, trg)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","            optimizer.step()\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        return epoch_loss / len(dataloader), epoch_acc / len(dataloader)\n","\n","    def _evaluate(self, model, dataloader, criterion):\n","        model.eval()\n","        epoch_loss = 0\n","        epoch_acc = 0\n","        with torch.no_grad():\n","            for i, (src, _, trg, _) in enumerate(dataloader):\n","                src, trg = src.long().to(DEVICE), trg.long().to(DEVICE)\n","                output = model(src, trg, 0)\n","                output_dim = output.shape[-1]\n","                output = output[1:].reshape(-1, output_dim)\n","                trg = trg[1:].reshape(-1)\n","                loss = criterion(output, trg)\n","                acc = self._accuracy(output, trg)\n","                epoch_loss += loss.item()\n","                epoch_acc += acc.item()\n","        return epoch_loss / len(dataloader), epoch_acc / len(dataloader)\n","\n","    def train(self, model, train_data, valid_data, optimizer, criterion, n_epochs, clip, teacher_forcing_ratio, lr_scheduler):\n","        best_valid_loss = float('inf')\n","        epochs_without_improvement = 0  # Initialize the counter\n","        patience = 3\n","\n","        for epoch in range(n_epochs):\n","            train_loss, train_acc = self._train_epoch(model, train_data, optimizer, criterion, clip, teacher_forcing_ratio)\n","            valid_loss, valid_acc = self._evaluate(model, valid_data, criterion)\n","\n","            self.train_losses.append(train_loss)\n","            self.val_losses.append(valid_loss)\n","            self.train_accuracies.append(train_acc)\n","            self.val_accuracies.append(valid_acc)\n","\n","            lr_scheduler.step(valid_loss)\n","\n","            if valid_loss < best_valid_loss:\n","                best_valid_loss = valid_loss\n","                epochs_without_improvement = 0  # Reset the counter\n","                torch.save(model.state_dict(), BASE_PATH + 'chatbot_model_best.pth')\n","            else:\n","                epochs_without_improvement += 1  # Increment the counter\n","\n","            print(f'Epoch: {epoch + 1:02}')\n","            print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n","            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')\n","\n","            # Check if early stopping criterion is met\n","            if epochs_without_improvement >= patience:\n","                print(\"Early stopping triggered! No improvement for\", epochs_without_improvement, \"epochs.\")\n","                break  # Stop training\n","\n","        torch.save(model.state_dict(), BASE_PATH + 'chatbot_model_final.pth')\n","\n","\n","    def plot_results(self):\n","        plt.figure(figsize=(10, 5))\n","        plt.subplot(1, 2, 1)\n","        plt.plot(self.train_losses, label=\"Training Loss\")\n","        plt.plot(self.val_losses, label=\"Validation Loss\")\n","        plt.legend()\n","        plt.title(\"Loss vs. Epochs\")\n","\n","        plt.subplot(1, 2, 2)\n","        plt.plot(self.train_accuracies, label=\"Training Accuracy\")\n","        plt.plot(self.val_accuracies, label=\"Validation Accuracy\")\n","        plt.legend()\n","        plt.title(\"Accuracy vs. Epochs\")\n","        plt.show()\n","\n","import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pth', save_model=False):\n","        \"\"\"\n","        Args:\n","            patience (int): Number of epochs to wait before stopping if no improvement is seen.\n","            verbose (bool): If True, prints a message for each validation loss improvement.\n","            delta (float): Minimum change in the validation loss to qualify as an improvement.\n","            path (str): Path for the checkpoint to be saved to.\n","            save_model (bool): If True, saves the entire model. Otherwise, only the state dict.\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.save_model = save_model\n","\n","    def __call__(self, val_loss, model):\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            if self.verbose:\n","                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        \"\"\"Saves model when validation loss decreases.\"\"\"\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        if self.save_model:\n","            torch.save(model, self.path)\n","        else:\n","            torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss\n","\n","\n","# --- SCRIPT/MAIN ----\n","if __name__ == \"__main__\":\n","    # Configuration\n","    BATCH_SIZE = 8\n","    EMB_DIM = 256\n","    HID_DIM = 1024\n","    N_LAYERS = 10\n","    DROPOUT = 0.2\n","    N_EPOCHS = 100\n","    CLIP = 1\n","    TEACHER_FORCING_RATIO = 0.5\n","    LEARNING_RATE = 0.0001\n","    train_ratio = 0.8\n","\n","    with open(BASE_PATH + \"preprocessed_data.pkl\", \"rb\") as file:\n","        preprocessed_data = pickle.load(file)\n","    tokenizer = preprocessed_data['tokenizer']\n","\n","    # Initialize the EarlyStopping class\n","    early_stopping = EarlyStopping(patience=3, verbose=True, path='chatbot_model_early_stopping_checkpoint.pth')\n","\n","    chatbot_trainer = ChatbotTrainer(data_path=BASE_PATH + \"preprocessed_data.pkl\", tokenizer=tokenizer)\n","\n","    # Splitting the dataset\n","    dataset = list(zip(chatbot_trainer.questions, chatbot_trainer.answers))\n","    train_size = int(train_ratio * len(dataset))\n","    valid_size = len(dataset) - train_size\n","    train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n","\n","    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=chatbot_trainer._collate_fn)\n","    valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=chatbot_trainer._collate_fn)\n","\n","    # Model Initialization and Training\n","    enc = Encoder(chatbot_trainer.input_dim, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT).to(DEVICE)\n","    dec = Decoder(chatbot_trainer.output_dim, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT).to(DEVICE)\n","    model = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n","\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","    PAD_IDX = chatbot_trainer.tokenizer.word_index['<pad>']\n","    criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n","    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n","\n","    # Train with early stopping\n","    # chatbot_trainer.train(model, train_dataloader, valid_dataloader, optimizer, criterion, N_EPOCHS, CLIP, TEACHER_FORCING_RATIO, lr_scheduler, early_stopping)\n","    # chatbot_trainer.train(model, train_dataloader, valid_dataloader, optimizer, criterion, N_EPOCHS, CLIP, TEACHER_FORCING_RATIO, lr_scheduler)\n","    # chatbot_trainer.plot_results()\n","    chatbot_trainer.train(model, train_dataloader, valid_dataloader, optimizer, criterion, N_EPOCHS, CLIP, TEACHER_FORCING_RATIO, lr_scheduler)\n","    chatbot_trainer.plot_results()"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"executionInfo":{"elapsed":21,"status":"error","timestamp":1692161380823,"user":{"displayName":"Vishal Patel","userId":"02637482279999814982"},"user_tz":240},"id":"3xz5ZSCxKY8l","outputId":"ede0ffa4-45da-48a1-bfae-26fc6e454f40"},"outputs":[{"ename":"AssertionError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-4244b139d8d8>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBASE_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"preprocessed_data.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mDEVICE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mresponder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatbotResponder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chatbot is ready to chat! Type 'exit' to end the chat.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-4244b139d8d8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, data_path, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mpreprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayout_map\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_coordinator_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtensor_api\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/keras_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# isort: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Preprocessing utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_space\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureSpace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Internal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/feature_space.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautocast_variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/mixed_precision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \"\"\"\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale_optimizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLossScaleOptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglobal_policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/mixed_precision/loss_scale_optimizer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdtensor_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madadelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madafactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madagrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adadelta.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_registration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_keras_serializable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;31m# Register the optimizer for loading from saved_model purpose.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m tf.__internal__.saved_model.load.register_revived_type(\n\u001b[0m\u001b[1;32m   1396\u001b[0m     \u001b[0;34m\"experimentalOptimizer\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/revived_types.py\u001b[0m in \u001b[0;36mregister_revived_type\u001b[0;34m(identifier, predicate, versions)\u001b[0m\n\u001b[1;32m    131\u001b[0m           \u001b[0;34mf\"Got multiple registrations with version {registration.version} for \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m           f\"type {identifier}.\")\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mversion_numbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregistration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0midentifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_REVIVED_TYPE_REGISTRY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Duplicate registrations for type 'experimentalOptimizer'"]}],"source":["# Test the chatbot result\n","import torch\n","import pickle\n","from torch.nn.utils.rnn import pad_sequence\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pickle\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from keras.callbacks import EarlyStopping\n","from torch.utils.data import random_split\n","import numpy as np\n","\n","\n","# ENCODER\n","class Encoder(nn.Module):\n","    \"\"\"Encoder module for the Seq2Seq model.\"\"\"\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, bidirectional=True)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src):\n","        embedded = self.dropout(self.embedding(src))\n","        outputs, (hidden, cell) = self.rnn(embedded)\n","        return hidden, cell\n","\n","# DECODER\n","class Decoder(nn.Module):\n","    \"\"\"Decoder module for the Seq2Seq model.\"\"\"\n","    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        self.output_dim = output_dim\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim, hid_dim * 2, n_layers, dropout=dropout)\n","        self.fc_out = nn.Linear(hid_dim * 2, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, input, hidden, cell):\n","        input = input.unsqueeze(0)\n","        embedded = self.dropout(self.embedding(input))\n","        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n","        prediction = self.fc_out(output.squeeze(0))\n","        return prediction, hidden, cell\n","\n","# SEQ2SEQ MODEL\n","class Seq2Seq(nn.Module):\n","    \"\"\"Main Seq2Seq model integrating the Encoder and Decoder.\"\"\"\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n","        trg_len = trg.shape[0]\n","        batch_size = trg.shape[1]\n","        trg_vocab_size = self.decoder.output_dim\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        encoder_hidden, encoder_cell = self.encoder(src)\n","\n","        if self.encoder.rnn.bidirectional:\n","            hidden = torch.cat((encoder_hidden[0:encoder_hidden.size(0):2],\n","                                encoder_hidden[1:encoder_hidden.size(0):2]), dim=2)\n","            cell = torch.cat((encoder_cell[0:encoder_cell.size(0):2],\n","                              encoder_cell[1:encoder_cell.size(0):2]), dim=2)\n","        else:\n","            hidden, cell = encoder_hidden, encoder_cell\n","\n","        input = trg[0]\n","\n","        for t in range(1, trg_len):\n","            output, hidden, cell = self.decoder(input, hidden, cell)\n","            outputs[t] = output\n","            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n","            top1 = output.argmax(1)\n","            input = trg[t] if teacher_force else top1\n","\n","        return outputs\n","\n","class ChatbotResponder:\n","    def __init__(self, model_path, data_path, device):\n","        self.device = device\n","        with open(data_path, \"rb\") as file:\n","            preprocessed_data = pickle.load(file)\n","        self.tokenizer = preprocessed_data['tokenizer']\n","        self.input_dim = len(self.tokenizer.word_index) + 1\n","        self.output_dim = len(self.tokenizer.word_index) + 1\n","        self.PAD_IDX = self.tokenizer.word_index['<pad>']\n","\n","        # Model Initialization\n","        EMB_DIM = 256\n","        HID_DIM = 512\n","        N_LAYERS = 2\n","        DROPOUT = 0.5\n","        self.enc = Encoder(self.input_dim, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT).to(self.device)\n","        self.dec = Decoder(self.output_dim, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT).to(self.device)\n","        self.model = Seq2Seq(self.enc, self.dec, self.device).to(self.device)\n","        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n","        self.model.eval()\n","\n","    def _tokenize(self, sentence):\n","        tokens = self.tokenizer.texts_to_sequences([sentence])\n","        return torch.tensor(tokens).to(self.device)\n","\n","    def _decode_tensor(self, tensor):\n","        decoded_words = []\n","        for tok_id in tensor:\n","            decoded_words.append(self.tokenizer.index_word[tok_id.item()])\n","            if tok_id.item() == self.tokenizer.word_index['<end>']:\n","                break\n","        return ' '.join(decoded_words[1:])\n","\n","    def generate_response(self, user_input):\n","        src_tensor = self._tokenize(user_input)\n","        with torch.no_grad():\n","            hidden, cell = self.enc(src_tensor)\n","            trg_indexes = [self.tokenizer.word_index['<start>']]\n","            for i in range(100):\n","                trg_tensor = torch.tensor([trg_indexes[-1]]).to(self.device)\n","                output, hidden, cell = self.dec(trg_tensor, hidden, cell)\n","                pred_token = output.argmax(1).item()\n","                trg_indexes.append(pred_token)\n","                if pred_token == self.tokenizer.word_index['<end>']:\n","                    break\n","        trg_tokens = torch.tensor(trg_indexes, dtype=torch.long)\n","        response = self._decode_tensor(trg_tokens)\n","        return response\n","\n","if __name__ == \"__main__\":\n","    model_path = \"/content/gdrive/MyDrive/Final/Immigration/chatbot_model_final.pth\"\n","    BASE_PATH = \"/content/gdrive/MyDrive/Final/Immigration/\"\n","    data_path = BASE_PATH + \"preprocessed_data.pkl\"\n","    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    responder = ChatbotResponder(model_path, data_path, DEVICE)\n","\n","    print(\"Chatbot is ready to chat! Type 'exit' to end the chat.\")\n","    while True:\n","        user_input = input(\"You: \")\n","        if user_input.lower() == 'exit':\n","            break\n","        response = responder.generate_response(user_input)\n","        print(\"Bot:\", response)\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMm3UC+FxOA++AGi6JzF5xM","gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
